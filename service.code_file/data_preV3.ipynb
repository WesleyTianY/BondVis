{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transactions data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chain_project.path_linking import summarize_paths, extract_database, merge_subsequences, prefix_span, restore_trades\n",
    "from chain_project.main import process_transactions\n",
    "\n",
    "def map_hashes_to_names(database):\n",
    "    # 生成一个唯一的名称映射\n",
    "    hash_to_name = {}\n",
    "    name_counter = 1\n",
    "    \n",
    "    for seq in database:\n",
    "        for hash_value in seq:\n",
    "            if hash_value not in hash_to_name:\n",
    "                hash_to_name[hash_value] = f\"Name{name_counter}\"\n",
    "                name_counter += 1\n",
    "    \n",
    "    # 使用名称映射替换哈希\n",
    "    mapped_database = []\n",
    "    for seq in database:\n",
    "        mapped_seq = [hash_to_name[hash_value] for hash_value in seq]\n",
    "        mapped_database.append(mapped_seq)\n",
    "    \n",
    "    return mapped_database, hash_to_name\n",
    "\n",
    "file_path='static/bond_2005496_2006_2402.csv'\n",
    "inst_list = ['长线资本基金孙姣', '国金证券股份严佳', '华创证券有限马延威', '潍坊银行股份王梓涵', '鄂尔多斯银行郭宁', '粤开证券股份周荃', '交通银行股份何嘉隆', '华源证券股份钱淑雯']\n",
    "\n",
    "data = process_transactions(file_path, inst_list)\n",
    "json_output = summarize_paths(data)\n",
    "trade_hashes = extract_database(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped Database:\n",
      "['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8']\n",
      "['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8']\n",
      "['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8']\n",
      "['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8']\n",
      "['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13']\n",
      "['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16']\n",
      "['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8']\n",
      "['Name3', 'Name9', 'Name10', 'Name14', 'Name18']\n",
      "['Name3', 'Name9', 'Name11', 'Name19', 'Name18']\n",
      "['Name9', 'Name10', 'Name19', 'Name18']\n",
      "['Name20', 'Name6', 'Name7', 'Name8']\n",
      "['Name21', 'Name11', 'Name19', 'Name18']\n",
      "['Name22', 'Name10', 'Name8']\n",
      "['Name22', 'Name11', 'Name8']\n",
      "['Name1', 'Name14', 'Name18']\n",
      "['Name1', 'Name23', 'Name24']\n",
      "['Name25', 'Name11', 'Name8']\n",
      "['Name1', 'Name23', 'Name26']\n",
      "['Name27', 'Name23', 'Name26']\n",
      "['Name21', 'Name11', 'Name8']\n",
      "['Name1', 'Name28']\n",
      "['Name1', 'Name8']\n",
      "['Name27', 'Name28']\n",
      "['Name27', 'Name8']\n",
      "['Name17', 'Name29']\n",
      "\n",
      "Hash to Name Mapping:\n",
      "133a7432cbaead2f7905ae0019b1946bcaf439964d0c2221fdfed64be6d186e2: Name1\n",
      "d0b0f07af7001e02e216e4bfde103bdf6c34c7763c48bed0b69aa030d925e91c: Name2\n",
      "3bfc9496a75f5000c5a247b59db75c5bc9cfd46f0585792f022f937983d9cd56: Name3\n",
      "0f7c1ce9fde6e38f0d42ddb4fe10eaf86b96ab5b1037a7cfc6cbf07a31199f16: Name4\n",
      "ce4729e6f1a04ebbbb1b9031903ca57078605344ca5a3d0948770e1d0960dd27: Name5\n",
      "74e1241e76b466c2580cce1d17ea3a6bb5a8e3fc4427d948f7a5870c4d7431ab: Name6\n",
      "8eae06d2f2a124dffe5694f1bcffb92233e77023b04091a41e48927a366d2002: Name7\n",
      "8148d0558c123572eb637a5a0b835eac93299a2c7018c8e090428fb88e97d246: Name8\n",
      "1bc7e7c5c6a12267298c8e5bcf3e8d1e469b23205081531ac01915cf8a997577: Name9\n",
      "c0aef1ceff15fd20f14856385fdd3f03c5e2700753c34234e9325fa29e6136c0: Name10\n",
      "deef03352aa43e1fef586f2fb39ae62bb0542898ab9d60c6dbaee063bd8bb74c: Name11\n",
      "c8c7957116101466ee89c10489819c0f9dd7a51608c09e4e0eac4a6e98dcf398: Name12\n",
      "d8723ad095ab1db2b442e79dec64cbb3994be0ae3a35c0ed973453e60e516bfe: Name13\n",
      "b4b7e06ba6977b1c73d605dd11fd4c49c00c57ada1094a10ed9e4296941a02b3: Name14\n",
      "c687c581488e304dbab22cd0e8b4beb228ce7bb5a434b5f501d6fcff0ecb163f: Name15\n",
      "a1d79c023a3536e8a9c11ded65b97d83cbdf338dcbcaae1a9fdf8951cf190e19: Name16\n",
      "79122a3079125c87c5c2bd38e643f18dff8a2cbf62d5e2dba8959e89d78ec447: Name17\n",
      "d2505e552d9dc8c2526561a921c4c89c74abfc1405aa0e65400d83dfa4130c9e: Name18\n",
      "9a7a5d4b228984bacc713a6fbc54c22e42e0fff99c5fbd441d76ffee2f672a20: Name19\n",
      "3be1d67c4f279c1eb95129d8c0472fa8340b9466ac6912d58dc78291e636e07c: Name20\n",
      "30ab8d34264c28adfeb9c7dd4a4a4ade41ee6c066d197f847b19597dab1f4fae: Name21\n",
      "f1f76a7354f42aa3973628ecaaf4f022bd2d5d8bfe71692cb1356dc04e695164: Name22\n",
      "27c05266f3b0b018202f3f367b780b08973a30ede1493d2cbf4d56bfd30bb102: Name23\n",
      "36e47452a7f6fed58b59d365a6fc488fa7d2035e75ec9f8c7b036ad6784b27b2: Name24\n",
      "9d46aede1369a557184a9bc3418d07e3e3f7601f149f7c36680ff0777a08696d: Name25\n",
      "4ca744927b8668e17dd4a4df0903900fe710b25b9b9ea1b9c8ef5e4fc28cd651: Name26\n",
      "f6ff417ec605e0ec26d5627088b34770e425a1ce01712a9f7640b5d4840d1f33: Name27\n",
      "c0c9fcbe31c9d1a734180cd2fb30f40d78aa7373bae381d0305f223867df457f: Name28\n",
      "d7a6c20efb6a649ec3c9170f7a9f8e79f31526a0ff49e1fec59c7e309f9b9d15: Name29\n"
     ]
    }
   ],
   "source": [
    "# 原始数据\n",
    "database = trade_hashes\n",
    "\n",
    "mapped_database, hash_to_name = map_hashes_to_names(database)\n",
    "\n",
    "# 打印结果\n",
    "print(\"Mapped Database:\")\n",
    "for seq in mapped_database:\n",
    "    print(seq)\n",
    "\n",
    "print(\"\\nHash to Name Mapping:\")\n",
    "for hash_value, name in hash_to_name.items():\n",
    "    print(f\"{hash_value}: {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 子路径subpath抽取算法设计\n",
    "\n",
    "现在我有一些交易路径路径，每条交易路径是一笔笔交易组成的，举例，每一笔交易的结构是这样的，将其append为list就是路径的list。\n",
    "\n",
    "    {\n",
    "        \"seller\": \"东海证券股份温妍超\",\n",
    "        \"buyer\": \"长线资本基金孙姣\",\n",
    "        \"volume\": 10,\n",
    "        \"price\": 110.36,\n",
    "        \"time_dl\": \"2023-12-06T16:44:13+08:00\",\n",
    "        \"trade_hash\": \"133a7432cbaead2f7905ae0019b1946bcaf439964d0c2221fdfed64be6d186e2\"\n",
    "      },\n",
    "\n",
    "其中有一个属性为trade_hash，用于标识交易唯一性。\n",
    "\n",
    "现在我有很多条这样的交易路径，我的目标是从中抽取出一些小的子路径，请你帮我设计出相关的算法。\n",
    "\n",
    "小的子路径的认定规则：1. 子路径在多条交易路径中出现。2.最小长度是3，越长越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 子路径生成算法的计算复杂度\n",
    "\n",
    "上述算法的计算复杂度可以从以下几个方面来分析：\n",
    "\n",
    "1. **生成子路径的复杂度**：\n",
    "   - 对于每条交易路径，长度为 \\( n \\)，生成所有长度大于等于 3 的子路径的复杂度大致为 \\( O(n^2) \\)。\n",
    "   - 这是因为在最坏情况下，每个起点可能生成 \\( n-2 \\) 个子路径（长度从 3 到 \\( n \\)），而总共有 \\( n \\) 个起点。\n",
    "\n",
    "2. **子路径的频率统计**：\n",
    "   - 假设有 \\( m \\) 条交易路径，每条路径的长度为 \\( n_i \\)。\n",
    "   - 子路径的生成和统计的总复杂度为 \\( O\\left(\\sum_{i=1}^m n_i^2\\right) \\)，其中 \\( n_i \\) 是第 \\( i \\) 条路径的长度。\n",
    "\n",
    "3. **子路径过滤和排序**：\n",
    "   - 过滤和排序的复杂度取决于子路径的数量。最坏情况下，子路径的数量可能接近所有路径的总长度的平方，因此排序复杂度为 \\( O(k \\log k) \\)，其中 \\( k \\) 是所有子路径的总数。\n",
    "\n",
    "### 总体复杂度\n",
    "- 因此，整个算法的时间复杂度大致为 \\( O\\left(\\sum_{i=1}^m n_i^2 + k \\log k\\right) \\)。\n",
    "- 当路径数量 \\( m \\) 较多，且路径长度较长时，算法的时间复杂度会变得较高。\n",
    "\n",
    "### 其他的算法\n",
    "\n",
    "1. **Trie（前缀树）算法**：\n",
    "   - 可以使用 Trie 数据结构存储所有路径的前缀或子路径。通过在 Trie 中进行深度优先搜索（DFS），可以找到多个路径中重复出现的子路径。\n",
    "   - 构建 Trie 的复杂度为 \\( O\\left(\\sum_{i=1}^m n_i\\right) \\)，但查找和过滤重复子路径的复杂度会有所降低。\n",
    "   - 优点是可以高效地共享公共前缀，减少冗余计算。\n",
    "\n",
    "2. **后缀数组 + LCP（Longest Common Prefix）算法**：\n",
    "   - 先将所有交易路径拼接成一个长字符串，使用后缀数组构建所有后缀的排序。然后使用 LCP 数组计算相邻后缀的最长公共前缀，这样可以找到重复子路径。\n",
    "   - 后缀数组的构建复杂度为 \\( O(N \\log N) \\)，其中 \\( N \\) 是所有路径长度之和。\n",
    "   - 这种方法特别适合路径数量非常大且路径之间具有较多相似性的情况。\n",
    "\n",
    "3. **基于频繁子序列挖掘的算法**：\n",
    "   - 可以使用频繁子序列挖掘算法（如 PrefixSpan、SPADE 等）来查找多个路径中频繁出现的子路径。这些算法通常用于序列数据的挖掘，能够有效处理子序列在不同路径中的频率。\n",
    "   - 复杂度依赖于数据的稀疏性和支持度阈值的选择。\n",
    "\n",
    "### 选择的依据\n",
    "- 如果你的路径数据量较大，且子路径有较多的重叠，那么 **Trie** 或 **后缀数组 + LCP** 可能会更高效。\n",
    "- 如果你希望发现更复杂的频繁子路径模式，或者路径数据存在一定的噪声，可以考虑使用 **频繁子序列挖掘算法**。\n",
    "\n",
    "不同算法的适用性取决于你的具体数据特性和性能需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_subsequences = prefix_span(mapped_database, [], min_support=1)\n",
    "# merged_subsequences = merge_subsequences(frequent_subsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent subsequences appearing in at least 2 sequences:\n",
      "Subsequence: ('Name5', 'Name6', 'Name7', 'Name8'), Count: 2\n",
      "Subsequence: ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'), Count: 2\n",
      "Subsequence: ('Name4', 'Name5', 'Name6', 'Name7'), Count: 2\n",
      "Subsequence: ('Name4', 'Name5', 'Name6'), Count: 2\n",
      "Subsequence: ('Name5', 'Name6', 'Name7'), Count: 2\n",
      "Subsequence: ('Name6', 'Name7', 'Name8'), Count: 3\n",
      "Subsequence: ('Name1', 'Name2', 'Name3'), Count: 5\n",
      "Subsequence: ('Name2', 'Name3', 'Name9'), Count: 4\n",
      "Subsequence: ('Name3', 'Name9', 'Name10'), Count: 3\n",
      "Subsequence: ('Name1', 'Name2', 'Name3', 'Name9'), Count: 4\n",
      "Subsequence: ('Name3', 'Name9', 'Name11'), Count: 2\n",
      "Subsequence: ('Name3', 'Name9', 'Name10', 'Name14'), Count: 2\n",
      "Subsequence: ('Name9', 'Name10', 'Name14'), Count: 2\n",
      "Subsequence: ('Name11', 'Name19', 'Name18'), Count: 2\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_subsequences(seq, min_length=1):\n",
    "    \"\"\"生成所有可能的子序列\"\"\"\n",
    "    subsequences = set()\n",
    "    n = len(seq)\n",
    "    for length in range(min_length, n + 1):\n",
    "        for start in range(n - length + 1):\n",
    "            subsequences.add(tuple(seq[start:start + length]))\n",
    "    return subsequences\n",
    "\n",
    "def find_frequent_subsequences(sequences, min_occurrences):\n",
    "    \"\"\"找到在至少min_occurrences个序列中出现的子序列\"\"\"\n",
    "    subseq_counts = defaultdict(int)\n",
    "    num_sequences = len(sequences)\n",
    "    \n",
    "    # 统计所有子序列的出现次数\n",
    "    for seq in sequences:\n",
    "        subsequences = generate_subsequences(seq, min_length=3)  # 子序列最小长度为3\n",
    "        unique_subsequences = set(subsequences)  # 去重\n",
    "        for subseq in unique_subsequences:\n",
    "            subseq_counts[subseq] += 1\n",
    "\n",
    "    # 过滤出在至少min_occurrences个序列中出现的子序列\n",
    "    frequent_subsequences = {subseq: count for subseq, count in subseq_counts.items() if count >= min_occurrences}\n",
    "    \n",
    "    return frequent_subsequences\n",
    "\n",
    "# 示例数据\n",
    "sequences = [\n",
    "    ['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16'],\n",
    "    ['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name18'],\n",
    "    ['Name3', 'Name9', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name9', 'Name10', 'Name19', 'Name18'],\n",
    "    ['Name20', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name21', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name22', 'Name10', 'Name8'],\n",
    "    ['Name22', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name14', 'Name18'],\n",
    "    ['Name1', 'Name23', 'Name24'],\n",
    "    ['Name25', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name23', 'Name26'],\n",
    "    ['Name27', 'Name23', 'Name26'],\n",
    "    ['Name21', 'Name11', 'Name8']\n",
    "]\n",
    "\n",
    "# 查找至少出现3次的频繁子序列\n",
    "min_occurrences = 2\n",
    "frequent_subsequences = find_frequent_subsequences(sequences, min_occurrences)\n",
    "print(f\"Frequent subsequences appearing in at least {min_occurrences} sequences:\")\n",
    "for subseq, count in frequent_subsequences.items():\n",
    "    print(f\"Subsequence: {subseq}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 现在有了很多的子序列，但是子序列之中有一些是另一些的子集，这样会导致重复计算，需要对子序列进行去重。\n",
    "# 去重的规则是 如果两个子序列，其中一个序列是另一个的子集\n",
    "# 1. 他们的重复次数相同，那么就将他们合并成一个子序列（保留更长的那一个）\n",
    "# 2. 重复次数不同，其中短的要更长一点，那边保留短的那个，否则就保留短的那一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique frequent subsequences appearing in at least 2 sequences:\n",
      "Subsequence: ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'), Count: 2\n",
      "Subsequence: ('Name1', 'Name2', 'Name3', 'Name9'), Count: 4\n",
      "Subsequence: ('Name3', 'Name9', 'Name10', 'Name14'), Count: 2\n",
      "Subsequence: ('Name3', 'Name9', 'Name11'), Count: 2\n",
      "Subsequence: ('Name11', 'Name19', 'Name18'), Count: 2\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "def generate_subsequences(seq, min_length=1):\n",
    "    \"\"\"生成所有可能的子序列\"\"\"\n",
    "    subsequences = set()\n",
    "    n = len(seq)\n",
    "    for length in range(min_length, n + 1):\n",
    "        for start in range(n - length + 1):\n",
    "            subsequences.add(tuple(seq[start:start + length]))\n",
    "    return subsequences\n",
    "\n",
    "def find_frequent_subsequences(sequences, min_occurrences):\n",
    "    \"\"\"找到在至少min_occurrences个序列中出现的子序列\"\"\"\n",
    "    subseq_counts = defaultdict(int)\n",
    "    num_sequences = len(sequences)\n",
    "    \n",
    "    # 统计所有子序列的出现次数\n",
    "    for seq in sequences:\n",
    "        subsequences = generate_subsequences(seq, min_length=3)  # 子序列最小长度为3\n",
    "        unique_subsequences = set(subsequences)  # 去重\n",
    "        for subseq in unique_subsequences:\n",
    "            subseq_counts[subseq] += 1\n",
    "\n",
    "    # 过滤出在至少min_occurrences个序列中出现的子序列\n",
    "    frequent_subsequences = {subseq: count for subseq, count in subseq_counts.items() if count >= min_occurrences}\n",
    "    \n",
    "    return frequent_subsequences\n",
    "\n",
    "def remove_subset_duplicates(subsequences):\n",
    "    \"\"\"去除子集重复的子序列\"\"\"\n",
    "    sorted_subsequences = sorted(subsequences.items(), key=lambda x: (-len(x[0]), -x[1]))  # 按长度和计数排序\n",
    "    unique_subsequences = {}\n",
    "    \n",
    "    for subseq, count in sorted_subsequences:\n",
    "        is_subset = False\n",
    "        for other_subseq in list(unique_subsequences.keys()):\n",
    "            if set(subseq).issubset(set(other_subseq)):\n",
    "                is_subset = True\n",
    "                if unique_subsequences[other_subseq] == count:\n",
    "                    # 如果两个子序列出现次数相同，保留更长的那一个\n",
    "                    if len(subseq) > len(other_subseq):\n",
    "                        del unique_subsequences[other_subseq]\n",
    "                        unique_subsequences[subseq] = count\n",
    "                break\n",
    "        if not is_subset:\n",
    "            unique_subsequences[subseq] = count\n",
    "    \n",
    "    return unique_subsequences\n",
    "\n",
    "# 示例数据\n",
    "sequences = [\n",
    "    ['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16'],\n",
    "    ['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name18'],\n",
    "    ['Name3', 'Name9', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name9', 'Name10', 'Name19', 'Name18'],\n",
    "    ['Name20', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name21', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name22', 'Name10', 'Name8'],\n",
    "    ['Name22', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name14', 'Name18'],\n",
    "    ['Name1', 'Name23', 'Name24'],\n",
    "    ['Name25', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name23', 'Name26'],\n",
    "    ['Name27', 'Name23', 'Name26'],\n",
    "    ['Name21', 'Name11', 'Name8']\n",
    "]\n",
    "\n",
    "# 查找至少出现2次的频繁子序列\n",
    "min_occurrences = 2\n",
    "frequent_subsequences = find_frequent_subsequences(sequences, min_occurrences)\n",
    "\n",
    "# 去除子集重复\n",
    "unique_subsequences = remove_subset_duplicates(frequent_subsequences)\n",
    "\n",
    "print(f\"Unique frequent subsequences appearing in at least {min_occurrences} sequences:\")\n",
    "for subseq, count in unique_subsequences.items():\n",
    "    print(f\"Subsequence: {subseq}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent subsequences appearing in at least 2 sequences:\n",
    "# Subsequence: ('Name5', 'Name6', 'Name7', 'Name8'), Count: 2\n",
    "# Subsequence: ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'), Count: 2\n",
    "# Subsequence: ('Name5', 'Name6', 'Name7'), Count: 2\n",
    "# Subsequence: ('Name6', 'Name7', 'Name8'), Count: 3\n",
    "# Subsequence: ('Name4', 'Name5', 'Name6', 'Name7'), Count: 2\n",
    "# Subsequence: ('Name1', 'Name2', 'Name3'), Count: 5\n",
    "# Subsequence: ('Name4', 'Name5', 'Name6'), Count: 2\n",
    "# Subsequence: ('Name3', 'Name9', 'Name10'), Count: 3\n",
    "# Subsequence: ('Name2', 'Name3', 'Name9'), Count: 4\n",
    "# Subsequence: ('Name1', 'Name2', 'Name3', 'Name9'), Count: 4\n",
    "# Subsequence: ('Name3', 'Name9', 'Name11'), Count: 2\n",
    "# Subsequence: ('Name9', 'Name10', 'Name14'), Count: 2\n",
    "# Subsequence: ('Name3', 'Name9', 'Name10', 'Name14'), Count: 2\n",
    "# Subsequence: ('Name11', 'Name19', 'Name18'), Count: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': [{'name': 'Name1', 'content': 'Name1'},\n",
       "  {'name': 'subsequence1', 'content': ['Name3', 'Name9', 'Name10']},\n",
       "  {'name': 'Name8', 'content': 'Name8'},\n",
       "  {'name': 'subsequence2', 'content': ['Name1', 'Name2', 'Name3']}],\n",
       " 'flows': [{'thru': ['Name1', 'Name2', 'subsequence1', 'Name8'], 'value': 1}]}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到了最小的子序列，接下来需要将转换到原本的链路内部，方法是从每条链路内部查找最小的子序列，然后将其替换到原链路上。\n",
    "\n",
    "{\n",
    "  \"nodes\":[\n",
    "    {\n",
    "      \"name\": 'Name1',  #随机生成一个\n",
    "      \"content\": 'Name1'\n",
    "    },\n",
    "    {\n",
    "      \"name\": 'subsequence1',  #随机生成一个\n",
    "      \"content\": ['Name3', 'Name9', 'Name10']\n",
    "    },\n",
    "    {\n",
    "      \"name\": 'Name8',  #随机生成一个\n",
    "      \"content\": 'Name8'\n",
    "    },\n",
    "    {\n",
    "      \"name\": 'subsequence' + '2',  #随机生成一个\n",
    "      \"content\": ['Name1', 'Name2', 'Name3']\n",
    "    }],\n",
    "  \"flows\":[\n",
    "    {\n",
    "      \"thru\": [\n",
    "        \"Name1\",\n",
    "        \"Name2\",\n",
    "        \"subsequence1\",\n",
    "        \"Name8\"\n",
    "      ],\n",
    "      \"value\": 1\n",
    "    },\n",
    "  ]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'name': 'subsequencelnduE', 'disp': ['Name4', 'Name5', 'Name6', 'Name7', 'Name8']}, {'name': 'subsequenceNInWL', 'disp': ['Name1', 'Name2', 'Name3', 'Name9']}, {'name': 'subsequenceQmS9H', 'disp': ['Name3', 'Name9', 'Name10', 'Name14']}, {'name': 'subsequenceGzK12', 'disp': ['Name3', 'Name9', 'Name11']}, {'name': 'subsequenceI6Mt8', 'disp': ['Name11', 'Name19', 'Name18']}, {'name': 'transactionEHd81', 'disp': 'Name17'}, {'name': 'transactionteLD4', 'disp': 'Name24'}, {'name': 'transactionEI2uP', 'disp': 'Name25'}, {'name': 'transactionIMDKj', 'disp': 'Name15'}, {'name': 'transactionAXVzH', 'disp': 'Name26'}, {'name': 'transactionAW2No', 'disp': 'Name16'}, {'name': 'transaction0Ryge', 'disp': 'Name12'}, {'name': 'transactionVyQNy', 'disp': 'Name22'}, {'name': 'transactionPSFNz', 'disp': 'Name27'}, {'name': 'transactionGd2cq', 'disp': 'Name20'}, {'name': 'transactionKQn6K', 'disp': 'Name23'}, {'name': 'transaction4LPif', 'disp': 'Name21'}, {'name': 'transactionA4NQf', 'disp': 'Name13'}], 'flows': [{'thru': ['Name1', 'Name2', 'Name3', 'subsequencelnduE'], 'value': 1}, {'thru': ['subsequenceNInWL', 'Name10', 'Name8'], 'value': 1}, {'thru': ['subsequenceNInWL', 'Name11', 'Name8'], 'value': 1}, {'thru': ['subsequenceNInWL', 'Name7', 'Name8'], 'value': 1}, {'thru': ['subsequenceNInWL', 'Name12', 'Name13'], 'value': 1}, {'thru': ['subsequenceQmS9H', 'Name15', 'Name16'], 'value': 1}, {'thru': ['Name17', 'subsequencelnduE'], 'value': 1}, {'thru': ['subsequenceQmS9H', 'Name18'], 'value': 1}, {'thru': ['subsequenceGzK12', 'Name19', 'Name18'], 'value': 1}, {'thru': ['Name9', 'Name10', 'Name19', 'Name18'], 'value': 1}, {'thru': ['Name20', 'Name6', 'Name7', 'Name8'], 'value': 1}, {'thru': ['Name21', 'subsequenceI6Mt8'], 'value': 1}, {'thru': ['Name22', 'Name10', 'Name8'], 'value': 1}, {'thru': ['Name22', 'Name11', 'Name8'], 'value': 1}, {'thru': ['Name1', 'Name14', 'Name18'], 'value': 1}, {'thru': ['Name1', 'Name23', 'Name24'], 'value': 1}, {'thru': ['Name25', 'Name11', 'Name8'], 'value': 1}, {'thru': ['Name1', 'Name23', 'Name26'], 'value': 1}, {'thru': ['Name27', 'Name23', 'Name26'], 'value': 1}, {'thru': ['Name21', 'Name11', 'Name8'], 'value': 1}]}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_name(prefix=''):\n",
    "    \"\"\"生成随机名称\"\"\"\n",
    "    return prefix + ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "\n",
    "def map_subsequences_to_nodes(subsequences):\n",
    "    \"\"\"将最小子序列映射到节点\"\"\"\n",
    "    node_map = {}\n",
    "    node_id = 1\n",
    "    for subseq in subsequences:\n",
    "        node_name = generate_random_name(prefix='subsequence')\n",
    "        node_map[subseq] = node_name\n",
    "    return node_map\n",
    "\n",
    "def identify_individual_transactions(sequences, subsequences):\n",
    "    \"\"\"识别单独交易\"\"\"\n",
    "    all_transactions = set(transaction for seq in sequences for transaction in seq)\n",
    "    subseq_transactions = set(transaction for subseq in subsequences for transaction in subseq)\n",
    "    individual_transactions = all_transactions - subseq_transactions\n",
    "    return individual_transactions\n",
    "\n",
    "def replace_subsequences_in_sequences(sequences, subsequences_map):\n",
    "    \"\"\"用节点名称替换原链路中的最小子序列\"\"\"\n",
    "    replaced_sequences = []\n",
    "    for seq in sequences:\n",
    "        replaced_seq = []\n",
    "        i = 0\n",
    "        while i < len(seq):\n",
    "            matched = False\n",
    "            for length in range(5, 2, -1):  # 从最长到最短检查\n",
    "                if i + length <= len(seq):\n",
    "                    sub = tuple(seq[i:i + length])\n",
    "                    if sub in subsequences_map:\n",
    "                        replaced_seq.append(subsequences_map[sub])\n",
    "                        i += length\n",
    "                        matched = True\n",
    "                        break\n",
    "            if not matched:\n",
    "                replaced_seq.append(seq[i])\n",
    "                i += 1\n",
    "        replaced_sequences.append(replaced_seq)\n",
    "    return replaced_sequences\n",
    "\n",
    "def generate_flows(sequences):\n",
    "    \"\"\"生成流动数据\"\"\"\n",
    "    flows = []\n",
    "    for seq in sequences:\n",
    "        flow = {\"thru\": seq, \"value\": 1}\n",
    "        flows.append(flow)\n",
    "    return flows\n",
    "\n",
    "# 最小子序列\n",
    "min_subsequences = [\n",
    "    ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'),\n",
    "    ('Name1', 'Name2', 'Name3', 'Name9'),\n",
    "    ('Name3', 'Name9', 'Name10', 'Name14'),\n",
    "    ('Name3', 'Name9', 'Name11'),\n",
    "    ('Name11', 'Name19', 'Name18')\n",
    "]\n",
    "\n",
    "# 原始数据\n",
    "sequences = [\n",
    "    ['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16'],\n",
    "    ['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name18'],\n",
    "    ['Name3', 'Name9', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name9', 'Name10', 'Name19', 'Name18'],\n",
    "    ['Name20', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name21', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name22', 'Name10', 'Name8'],\n",
    "    ['Name22', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name14', 'Name18'],\n",
    "    ['Name1', 'Name23', 'Name24'],\n",
    "    ['Name25', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name23', 'Name26'],\n",
    "    ['Name27', 'Name23', 'Name26'],\n",
    "    ['Name21', 'Name11', 'Name8']\n",
    "]\n",
    "\n",
    "# 生成节点映射\n",
    "node_map = map_subsequences_to_nodes(min_subsequences)\n",
    "\n",
    "# 识别单独交易\n",
    "individual_transactions = identify_individual_transactions(sequences, min_subsequences)\n",
    "\n",
    "# 将单独交易也加入到节点映射中\n",
    "for transaction in individual_transactions:\n",
    "    node_map[tuple([transaction])] = generate_random_name(prefix='transaction')\n",
    "\n",
    "# 将原始数据中的子序列替换为节点名称\n",
    "replaced_sequences = replace_subsequences_in_sequences(sequences, node_map)\n",
    "\n",
    "# 生成流动数据\n",
    "flows = generate_flows(replaced_sequences)\n",
    "\n",
    "# 生成最终结果\n",
    "result = {\n",
    "    \"nodes\": [\n",
    "        {\"name\": node_map[('Name4', 'Name5', 'Name6', 'Name7', 'Name8')], \"disp\": ['Name4', 'Name5', 'Name6', 'Name7', 'Name8']},\n",
    "        {\"name\": node_map[('Name1', 'Name2', 'Name3', 'Name9')], \"disp\": ['Name1', 'Name2', 'Name3', 'Name9']},\n",
    "        {\"name\": node_map[('Name3', 'Name9', 'Name10', 'Name14')], \"disp\": ['Name3', 'Name9', 'Name10', 'Name14']},\n",
    "        {\"name\": node_map[('Name3', 'Name9', 'Name11')], \"disp\": ['Name3', 'Name9', 'Name11']},\n",
    "        {\"name\": node_map[('Name11', 'Name19', 'Name18')], \"disp\": ['Name11', 'Name19', 'Name18']},\n",
    "        *[\n",
    "            {\"name\": node_map[tuple([transaction])], \"disp\": transaction}\n",
    "            for transaction in individual_transactions\n",
    "        ]\n",
    "    ],\n",
    "    \"flows\": flows\n",
    "}\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# # 将结果保存为 JSON 文件\n",
    "# with open('data.json', 'w') as f:\n",
    "#     json.dump(result, f, indent=4)\n",
    "\n",
    "# print(\"结果已保存为 result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import json\n",
    "\n",
    "def generate_random_name(prefix=''):\n",
    "    \"\"\"生成随机名称\"\"\"\n",
    "    return prefix + ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "\n",
    "def map_subsequences_to_nodes(subsequences):\n",
    "    \"\"\"将最小子序列映射到节点\"\"\"\n",
    "    node_map = {}\n",
    "    node_id = 1\n",
    "    for subseq in subsequences:\n",
    "        node_name = generate_random_name(prefix='subsequence')\n",
    "        node_map[subseq] = node_name\n",
    "    return node_map\n",
    "\n",
    "def identify_individual_transactions(sequences, subsequences):\n",
    "    \"\"\"识别单独交易\"\"\"\n",
    "    all_transactions = set(transaction for seq in sequences for transaction in seq)\n",
    "    subseq_transactions = set(transaction for subseq in subsequences for transaction in subseq)\n",
    "    individual_transactions = all_transactions - subseq_transactions\n",
    "    return individual_transactions\n",
    "\n",
    "def replace_subsequences_in_sequences(sequences, subsequences_map):\n",
    "    \"\"\"用节点名称替换原链路中的最小子序列\"\"\"\n",
    "    replaced_sequences = []\n",
    "    for seq in sequences:\n",
    "        replaced_seq = []\n",
    "        i = 0\n",
    "        while i < len(seq):\n",
    "            matched = False\n",
    "            for length in range(5, 2, -1):  # 从最长到最短检查\n",
    "                if i + length <= len(seq):\n",
    "                    sub = tuple(seq[i:i + length])\n",
    "                    if sub in subsequences_map:\n",
    "                        replaced_seq.append(subsequences_map[sub])\n",
    "                        i += length\n",
    "                        matched = True\n",
    "                        break\n",
    "            if not matched:\n",
    "                replaced_seq.append(seq[i])\n",
    "                i += 1\n",
    "        replaced_sequences.append(replaced_seq)\n",
    "    return replaced_sequences\n",
    "\n",
    "def generate_flows(sequences, node_map):\n",
    "    \"\"\"生成流动数据\"\"\"\n",
    "    flows = []\n",
    "    for seq in sequences:\n",
    "        flow = {\"thru\": [node_map.get(item, item) for item in seq], \"value\": 1}\n",
    "        flows.append(flow)\n",
    "    return flows\n",
    "\n",
    "def format_nodes(node_map, individual_transactions):\n",
    "    \"\"\"格式化节点\"\"\"\n",
    "    nodes = []\n",
    "    for subseq, name in node_map.items():\n",
    "        nodes.append({\"disp\": ', '.join(subseq), \"name\": name})\n",
    "    for transaction in individual_transactions:\n",
    "        transaction_name = generate_random_name(prefix='transaction')\n",
    "        nodes.append({\"disp\": transaction, \"name\": transaction_name})\n",
    "    return nodes\n",
    "\n",
    "def add_missing_nodes(flows, nodes):\n",
    "    \"\"\"检查并补齐缺失的节点\"\"\"\n",
    "    nodes_set = set(node[\"name\"] for node in nodes)\n",
    "    missing_nodes = set()\n",
    "    \n",
    "    for flow in flows:\n",
    "        for item in flow[\"thru\"]:\n",
    "            if item not in nodes_set:\n",
    "                missing_nodes.add(item)\n",
    "\n",
    "    for missing in missing_nodes:\n",
    "        node_name = generate_random_name(prefix='transaction')\n",
    "        nodes.append({\"disp\": missing, \"name\": node_name})\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "# 最小子序列\n",
    "min_subsequences = [\n",
    "    ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'),\n",
    "    ('Name1', 'Name2', 'Name3', 'Name9'),\n",
    "    ('Name3', 'Name9', 'Name10', 'Name14'),\n",
    "    ('Name3', 'Name9', 'Name11'),\n",
    "    ('Name11', 'Name19', 'Name18')\n",
    "]\n",
    "\n",
    "# 原始数据\n",
    "sequences = [\n",
    "    ['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16'],\n",
    "    ['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name18'],\n",
    "    ['Name3', 'Name9', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name9', 'Name10', 'Name19', 'Name18'],\n",
    "    ['Name20', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name21', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name22', 'Name10', 'Name8'],\n",
    "    ['Name22', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name14', 'Name18'],\n",
    "    ['Name1', 'Name23', 'Name24'],\n",
    "    ['Name25', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name23', 'Name26'],\n",
    "    ['Name27', 'Name23', 'Name26'],\n",
    "    ['Name21', 'Name11', 'Name8']\n",
    "]\n",
    "\n",
    "# 生成节点映射\n",
    "node_map = map_subsequences_to_nodes(min_subsequences)\n",
    "\n",
    "# 识别单独交易\n",
    "individual_transactions = identify_individual_transactions(sequences, min_subsequences)\n",
    "\n",
    "# 将单独交易也加入到节点映射中\n",
    "for transaction in individual_transactions:\n",
    "    node_map[tuple([transaction])] = generate_random_name(prefix='transaction')\n",
    "\n",
    "# 将原始数据中的子序列替换为节点名称\n",
    "replaced_sequences = replace_subsequences_in_sequences(sequences, node_map)\n",
    "\n",
    "# 生成流动数据\n",
    "flows = generate_flows(replaced_sequences, node_map)\n",
    "\n",
    "# 格式化节点\n",
    "nodes = format_nodes(node_map, individual_transactions)\n",
    "\n",
    "# 检查并补齐缺失的节点\n",
    "nodes = add_missing_nodes(flows, nodes)\n",
    "\n",
    "# 生成最终结果\n",
    "result = {\n",
    "    \"Data source\": \"[Robert J. MacG. Dawson](http://www.amstat.org/publications/jse/v3n3/datasets.dawson.html)\",\n",
    "    \"nodes\": nodes,\n",
    "    \"flows\": flows\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'disp': ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'), 'name': 'subsequenceVL5uE'}, {'disp': ('Name1', 'Name2', 'Name3', 'Name9'), 'name': 'subsequencenXHbx'}, {'disp': ('Name3', 'Name9', 'Name10', 'Name14'), 'name': 'subsequencezRnK3'}, {'disp': ('Name3', 'Name9', 'Name11'), 'name': 'subsequence9vJe8'}, {'disp': ('Name11', 'Name19', 'Name18'), 'name': 'subsequence805IX'}, {'disp': 'Name7', 'name': 'transaction2uNYu'}, {'disp': 'Name25', 'name': 'transactiondXBzU'}, {'disp': 'Name16', 'name': 'transaction52ZFc'}, {'disp': 'Name14', 'name': 'transactionOs82d'}, {'disp': 'Name21', 'name': 'transactionRbHON'}, {'disp': 'Name19', 'name': 'transactionnNRU3'}, {'disp': 'Name9', 'name': 'transactionOdZC4'}, {'disp': 'Name24', 'name': 'transactionm4Ie4'}, {'disp': 'Name4', 'name': 'transactionX1gbo'}, {'disp': 'Name1', 'name': 'transactionimO75'}, {'disp': 'Name12', 'name': 'transactionkj8lg'}, {'disp': 'Name23', 'name': 'transactionNpyIB'}, {'disp': 'Name13', 'name': 'transactionjJ0FQ'}, {'disp': 'Name17', 'name': 'transactionmKl60'}, {'disp': 'Name15', 'name': 'transactionUvR9l'}, {'disp': 'Name18', 'name': 'transactionBQ3Wa'}, {'disp': 'Name5', 'name': 'transactiontId77'}, {'disp': 'Name10', 'name': 'transactionHH3KA'}, {'disp': 'Name6', 'name': 'transaction3QLu2'}, {'disp': 'Name2', 'name': 'transactionxIsLN'}, {'disp': 'Name11', 'name': 'transaction6Ilgx'}, {'disp': 'Name20', 'name': 'transactionVOJOq'}, {'disp': 'Name3', 'name': 'transaction5SDnZ'}, {'disp': 'Name22', 'name': 'transactionPwQaP'}, {'disp': 'Name27', 'name': 'transactionabsGo'}, {'disp': 'Name8', 'name': 'transactionUsOfw'}, {'disp': 'Name26', 'name': 'transactionjeype'}, {'disp': 'Name7', 'name': 'transactionIWLAB'}, {'disp': 'Name25', 'name': 'transactionN6lLW'}, {'disp': 'Name16', 'name': 'transactionVj8wz'}, {'disp': 'Name14', 'name': 'transactionUt2Bv'}, {'disp': 'Name21', 'name': 'transactionxkheY'}, {'disp': 'Name19', 'name': 'transactionq6WFf'}, {'disp': 'Name9', 'name': 'transactioneh03O'}, {'disp': 'Name24', 'name': 'transactionua9bb'}, {'disp': 'Name4', 'name': 'transactionPMM77'}, {'disp': 'Name1', 'name': 'transactionqtwkp'}, {'disp': 'Name12', 'name': 'transactionjGncR'}, {'disp': 'Name23', 'name': 'transaction4dfHz'}, {'disp': 'Name13', 'name': 'transactionOzExb'}, {'disp': 'Name17', 'name': 'transactionzLfAe'}, {'disp': 'Name15', 'name': 'transactionPsGHF'}, {'disp': 'Name18', 'name': 'transaction0ncu5'}, {'disp': 'Name5', 'name': 'transactiontK4O6'}, {'disp': 'Name10', 'name': 'transactionl5VB8'}, {'disp': 'Name6', 'name': 'transactionAkwAD'}, {'disp': 'Name2', 'name': 'transactionigxxJ'}, {'disp': 'Name11', 'name': 'transactiontLds4'}, {'disp': 'Name20', 'name': 'transactionnoU5S'}, {'disp': 'Name3', 'name': 'transactionESezP'}, {'disp': 'Name22', 'name': 'transactionlu5XK'}, {'disp': 'Name27', 'name': 'transactionwRaVB'}, {'disp': 'Name8', 'name': 'transactiongg5OI'}, {'disp': 'Name26', 'name': 'transactionHgHrj'}], 'flows': [{'thru': ['transactionimO75', 'transactionxIsLN', 'transaction5SDnZ', 'subsequenceVL5uE'], 'value': 1}, {'thru': ['subsequencenXHbx', 'transactionHH3KA', 'transactionUsOfw'], 'value': 1}, {'thru': ['subsequencenXHbx', 'transaction6Ilgx', 'transactionUsOfw'], 'value': 1}, {'thru': ['subsequencenXHbx', 'transaction2uNYu', 'transactionUsOfw'], 'value': 1}, {'thru': ['subsequencenXHbx', 'transactionkj8lg', 'transactionjJ0FQ'], 'value': 1}, {'thru': ['subsequencezRnK3', 'transactionUvR9l', 'transaction52ZFc'], 'value': 1}, {'thru': ['transactionmKl60', 'subsequenceVL5uE'], 'value': 1}, {'thru': ['subsequencezRnK3', 'transactionBQ3Wa'], 'value': 1}, {'thru': ['subsequence9vJe8', 'transactionnNRU3', 'transactionBQ3Wa'], 'value': 1}, {'thru': ['transactionOdZC4', 'transactionHH3KA', 'transactionnNRU3', 'transactionBQ3Wa'], 'value': 1}, {'thru': ['transactionVOJOq', 'transaction3QLu2', 'transaction2uNYu', 'transactionUsOfw'], 'value': 1}, {'thru': ['transactionRbHON', 'subsequence805IX'], 'value': 1}, {'thru': ['transactionPwQaP', 'transactionHH3KA', 'transactionUsOfw'], 'value': 1}, {'thru': ['transactionPwQaP', 'transaction6Ilgx', 'transactionUsOfw'], 'value': 1}, {'thru': ['transactionimO75', 'transactionOs82d', 'transactionBQ3Wa'], 'value': 1}, {'thru': ['transactionimO75', 'transactionNpyIB', 'transactionm4Ie4'], 'value': 1}, {'thru': ['transactiondXBzU', 'transaction6Ilgx', 'transactionUsOfw'], 'value': 1}, {'thru': ['transactionimO75', 'transactionNpyIB', 'transactionjeype'], 'value': 1}, {'thru': ['transactionabsGo', 'transactionNpyIB', 'transactionjeype'], 'value': 1}, {'thru': ['transactionRbHON', 'transaction6Ilgx', 'transactionUsOfw'], 'value': 1}]}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_name(prefix=''):\n",
    "    \"\"\"生成随机名称\"\"\"\n",
    "    return prefix + ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "\n",
    "def map_subsequences_to_nodes(subsequences):\n",
    "    \"\"\"将最小子序列映射到节点\"\"\"\n",
    "    node_map = {}\n",
    "    node_id = 1\n",
    "    for subseq in subsequences:\n",
    "        node_name = generate_random_name(prefix='subsequence')\n",
    "        node_map[subseq] = node_name\n",
    "    return node_map\n",
    "\n",
    "def identify_individual_transactions(sequences, subsequences):\n",
    "    \"\"\"识别单独交易\"\"\"\n",
    "    all_transactions = set(transaction for seq in sequences for transaction in seq)\n",
    "    subseq_transactions = set(transaction for subseq in subsequences for transaction in subseq)\n",
    "    individual_transactions = all_transactions\n",
    "    return individual_transactions\n",
    "\n",
    "def replace_subsequences_in_sequences(sequences, subsequences_map):\n",
    "    \"\"\"用节点名称替换原链路中的最小子序列\"\"\"\n",
    "    replaced_sequences = []\n",
    "    for seq in sequences:\n",
    "        replaced_seq = []\n",
    "        i = 0\n",
    "        while i < len(seq):\n",
    "            matched = False\n",
    "            for length in range(5, 2, -1):  # 从最长到最短检查\n",
    "                if i + length <= len(seq):\n",
    "                    sub = tuple(seq[i:i + length])\n",
    "                    if sub in subsequences_map:\n",
    "                        replaced_seq.append(subsequences_map[sub])\n",
    "                        i += length\n",
    "                        matched = True\n",
    "                        break\n",
    "            if not matched:\n",
    "                replaced_seq.append(node_map[seq[i]])\n",
    "                i += 1\n",
    "        replaced_sequences.append(replaced_seq)\n",
    "    return replaced_sequences\n",
    "\n",
    "def generate_flows(sequences, node_map):\n",
    "    \"\"\"生成流动数据\"\"\"\n",
    "    flows = []\n",
    "    for seq in sequences:\n",
    "        flow = {\"thru\": [node_map.get(x, x) for x in seq], \"value\": 1}\n",
    "        flows.append(flow)\n",
    "    return flows\n",
    "\n",
    "def format_nodes(node_map, individual_transactions):\n",
    "    \"\"\"格式化节点\"\"\"\n",
    "    nodes = []\n",
    "    for subseq, name in node_map.items():\n",
    "        nodes.append({\"disp\": subseq, \"name\": name})\n",
    "    for transaction in individual_transactions:\n",
    "        transaction_name = generate_random_name(prefix='transaction')\n",
    "        nodes.append({\"disp\": transaction, \"name\": transaction_name})\n",
    "        node_map[transaction] = transaction_name  # Ensure the transaction is included in the map\n",
    "    return nodes\n",
    "\n",
    "# 最小子序列\n",
    "min_subsequences = [\n",
    "    ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'),\n",
    "    ('Name1', 'Name2', 'Name3', 'Name9'),\n",
    "    ('Name3', 'Name9', 'Name10', 'Name14'),\n",
    "    ('Name3', 'Name9', 'Name11'),\n",
    "    ('Name11', 'Name19', 'Name18')\n",
    "]\n",
    "\n",
    "# 原始数据\n",
    "sequences = [\n",
    "    ['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16'],\n",
    "    ['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name18'],\n",
    "    ['Name3', 'Name9', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name9', 'Name10', 'Name19', 'Name18'],\n",
    "    ['Name20', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name21', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name22', 'Name10', 'Name8'],\n",
    "    ['Name22', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name14', 'Name18'],\n",
    "    ['Name1', 'Name23', 'Name24'],\n",
    "    ['Name25', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name23', 'Name26'],\n",
    "    ['Name27', 'Name23', 'Name26'],\n",
    "    ['Name21', 'Name11', 'Name8']\n",
    "]\n",
    "\n",
    "# 生成节点映射\n",
    "node_map = map_subsequences_to_nodes(min_subsequences)\n",
    "\n",
    "# 识别单独交易\n",
    "individual_transactions = identify_individual_transactions(sequences, min_subsequences)\n",
    "\n",
    "# 生成每笔交易的节点映射\n",
    "for transaction in individual_transactions:\n",
    "    node_map[transaction] = generate_random_name(prefix='transaction')\n",
    "\n",
    "# 将原始数据中的子序列替换为节点名称\n",
    "replaced_sequences = replace_subsequences_in_sequences(sequences, node_map)\n",
    "\n",
    "# 生成流动数据\n",
    "flows = generate_flows(replaced_sequences, node_map)\n",
    "\n",
    "# 格式化节点\n",
    "nodes = format_nodes(node_map, individual_transactions)\n",
    "\n",
    "# 生成最终结果\n",
    "result = {\n",
    "    \"nodes\": nodes,\n",
    "    \"flows\": flows\n",
    "}\n",
    "\n",
    "print(result)\n",
    "\n",
    "# 保存为 JSON 文件\n",
    "with open('result_with_check.json', 'w') as f:\n",
    "    json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最小子序列\n",
    "min_subsequences = [\n",
    "    ('Name4', 'Name5', 'Name6', 'Name7', 'Name8'),\n",
    "    ('Name1', 'Name2', 'Name3', 'Name9'),\n",
    "    ('Name3', 'Name9', 'Name10', 'Name14'),\n",
    "    ('Name3', 'Name9', 'Name11'),\n",
    "    ('Name11', 'Name19', 'Name18')\n",
    "]\n",
    "\n",
    "# 原始数据\n",
    "sequences = [\n",
    "    ['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16'],\n",
    "    ['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name18'],\n",
    "    ['Name3', 'Name9', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name9', 'Name10', 'Name19', 'Name18'],\n",
    "    ['Name20', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name21', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name22', 'Name10', 'Name8'],\n",
    "    ['Name22', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name14', 'Name18'],\n",
    "    ['Name1', 'Name23', 'Name24'],\n",
    "    ['Name25', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name23', 'Name26'],\n",
    "    ['Name27', 'Name23', 'Name26'],\n",
    "    ['Name21', 'Name11', 'Name8']\n",
    "]\n",
    "\n",
    "#TODO: 应该是在原始数据中的每条sequence中将最小子序列的元素去掉，得到一段一段的新的序列，再对新序列进行上述的一波操作。\n",
    "# 中间被去掉的元素应该找个东西当做占位符 前后被剪断的部分和中间的占位符用一个list包起来，这样再下一轮的最小子序列迭代过程中就可以更细粒度了。\n",
    "def identify_individual_transactions(sequences, subsequences):\n",
    "    \"\"\"识别单独交易\"\"\"\n",
    "    all_transactions = set(transaction for seq in sequences for transaction in seq)\n",
    "    subseq_transactions = set(transaction for subseq in subsequences for transaction in subseq)\n",
    "    individual_transactions = all_transactions\n",
    "    return individual_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed_subsequences {('Name3', 'Name9', 'Name10', 'Name14'), ('Name4', 'Name5', 'Name6', 'Name7'), ('Name5', 'Name6', 'Name7', 'Name8'), ('Name1', 'Name2', 'Name3', 'Name9')}\n",
      "removed_subsequences {('Name5', 'Name6', 'Name7', 'Name8'), ('Name11', 'Name19', 'Name18'), ('Name3', 'Name9', 'Name10', 'Name14'), ('Name4', 'Name5', 'Name6', 'Name7'), ('Name1', 'Name2', 'Name3', 'Name9')}\n",
      "removed_subsequences {('Name5', 'Name6', 'Name7', 'Name8'), ('Name21', 'Name11'), ('Name11', 'Name19', 'Name18'), ('Name3', 'Name9', 'Name10', 'Name14'), ('Name4', 'Name5', 'Name6', 'Name7'), ('Name11', 'Name8'), ('Name19', 'Name18'), ('Name10', 'Name8'), ('Name11', 'Name19'), ('Name23', 'Name26'), ('Name7', 'Name8'), ('Name1', 'Name23'), ('Name1', 'Name2', 'Name3', 'Name9')}\n",
      "node_map {('Name4', 'Name5', 'Name6', 'Name7'): '<removed_4>ERt4d', ('Name5', 'Name6', 'Name7', 'Name8'): '<removed_4>XPWmM', ('Name1', 'Name2', 'Name3', 'Name9'): '<removed_4>hOrdY', ('Name3', 'Name9', 'Name10', 'Name14'): '<removed_4>Ru6rL', ('Name11', 'Name19', 'Name18'): '<removed_3>gahOd', ('Name10', 'Name8'): '<removed_2>pHWib', ('Name11', 'Name8'): '<removed_2>PjouF', ('Name7', 'Name8'): '<removed_2>oAHWO', ('Name11', 'Name19'): '<removed_2>K7usF', ('Name19', 'Name18'): '<removed_2>5LgPl', ('Name21', 'Name11'): '<removed_2>zyMKY', ('Name1', 'Name23'): '<removed_2>wGSxr', ('Name23', 'Name26'): '<removed_2>X760B', 'Name1': 'transactionslTfQ', 'Name2': 'transactionW1s1f', 'Name3': 'transactioncUy0R', '<removed_4>ERt4d': 'transactionpF9ZR', 'Name8': 'transactiongxDaL', '<removed_4>hOrdY': 'transactionpys2p', '<removed_2>pHWib': 'transaction0uSMI', '<removed_2>PjouF': 'transactionWIeJ7', '<removed_2>oAHWO': 'transactionf9nWO', 'Name12': 'transactionofG7r', 'Name13': 'transactionZIKky', '<removed_4>Ru6rL': 'transactionGk0J9', 'Name15': 'transactionLumFi', 'Name16': 'transaction3513f', 'Name17': 'transactionxEKhW', 'Name18': 'transactioneq53y', 'Name9': 'transactionQmilP', '<removed_2>K7usF': 'transactionBJYL4', 'Name10': 'transactionZu7GN', '<removed_2>5LgPl': 'transactionYRE5t', 'Name20': 'transactiong8aLK', 'Name6': 'transactionEfkJq', '<removed_2>zyMKY': 'transactionnb1Rh', 'Name22': 'transactionh98w1', 'Name14': 'transactionyWNrI', '<removed_2>wGSxr': 'transaction2UE7q', 'Name24': 'transaction4FmhG', 'Name25': 'transactionZVCxv', 'Name26': 'transactionDgcGW', 'Name27': 'transactionXWVmd', '<removed_2>X760B': 'transactionz6o3P'}\n",
      "{'Data source': '[Robert J. MacG. Dawson](http://www.amstat.org/publications/jse/v3n3/datasets.dawson.html)', 'nodes': [{'disp': ('Name4', 'Name5', 'Name6', 'Name7'), 'name': '<removed_4>ERt4d'}, {'disp': ('Name5', 'Name6', 'Name7', 'Name8'), 'name': '<removed_4>XPWmM'}, {'disp': ('Name1', 'Name2', 'Name3', 'Name9'), 'name': '<removed_4>hOrdY'}, {'disp': ('Name3', 'Name9', 'Name10', 'Name14'), 'name': '<removed_4>Ru6rL'}, {'disp': ('Name11', 'Name19', 'Name18'), 'name': '<removed_3>gahOd'}, {'disp': ('Name10', 'Name8'), 'name': '<removed_2>pHWib'}, {'disp': ('Name11', 'Name8'), 'name': '<removed_2>PjouF'}, {'disp': ('Name7', 'Name8'), 'name': '<removed_2>oAHWO'}, {'disp': ('Name11', 'Name19'), 'name': '<removed_2>K7usF'}, {'disp': ('Name19', 'Name18'), 'name': '<removed_2>5LgPl'}, {'disp': ('Name21', 'Name11'), 'name': '<removed_2>zyMKY'}, {'disp': ('Name1', 'Name23'), 'name': '<removed_2>wGSxr'}, {'disp': ('Name23', 'Name26'), 'name': '<removed_2>X760B'}, {'disp': 'Name1', 'name': 'transactionslTfQ'}, {'disp': 'Name2', 'name': 'transactionW1s1f'}, {'disp': 'Name3', 'name': 'transactioncUy0R'}, {'disp': '<removed_4>ERt4d', 'name': 'transactionpF9ZR'}, {'disp': 'Name8', 'name': 'transactiongxDaL'}, {'disp': '<removed_4>hOrdY', 'name': 'transactionpys2p'}, {'disp': '<removed_2>pHWib', 'name': 'transaction0uSMI'}, {'disp': '<removed_2>PjouF', 'name': 'transactionWIeJ7'}, {'disp': '<removed_2>oAHWO', 'name': 'transactionf9nWO'}, {'disp': 'Name12', 'name': 'transactionofG7r'}, {'disp': 'Name13', 'name': 'transactionZIKky'}, {'disp': '<removed_4>Ru6rL', 'name': 'transactionGk0J9'}, {'disp': 'Name15', 'name': 'transactionLumFi'}, {'disp': 'Name16', 'name': 'transaction3513f'}, {'disp': 'Name17', 'name': 'transactionxEKhW'}, {'disp': 'Name18', 'name': 'transactioneq53y'}, {'disp': 'Name9', 'name': 'transactionQmilP'}, {'disp': '<removed_2>K7usF', 'name': 'transactionBJYL4'}, {'disp': 'Name10', 'name': 'transactionZu7GN'}, {'disp': '<removed_2>5LgPl', 'name': 'transactionYRE5t'}, {'disp': 'Name20', 'name': 'transactiong8aLK'}, {'disp': 'Name6', 'name': 'transactionEfkJq'}, {'disp': '<removed_2>zyMKY', 'name': 'transactionnb1Rh'}, {'disp': 'Name22', 'name': 'transactionh98w1'}, {'disp': 'Name14', 'name': 'transactionyWNrI'}, {'disp': '<removed_2>wGSxr', 'name': 'transaction2UE7q'}, {'disp': 'Name24', 'name': 'transaction4FmhG'}, {'disp': 'Name25', 'name': 'transactionZVCxv'}, {'disp': 'Name26', 'name': 'transactionDgcGW'}, {'disp': 'Name27', 'name': 'transactionXWVmd'}, {'disp': '<removed_2>X760B', 'name': 'transactionz6o3P'}], 'flows': [{'thru': ['transactionslTfQ', 'transactionW1s1f', 'transactioncUy0R', 'transactionpF9ZR', 'transactiongxDaL'], 'value': 1}, {'thru': ['transactionpys2p', 'transaction0uSMI'], 'value': 1}, {'thru': ['transactionpys2p', 'transactionWIeJ7'], 'value': 1}, {'thru': ['transactionpys2p', 'transactionf9nWO'], 'value': 1}, {'thru': ['transactionpys2p', 'transactionofG7r', 'transactionZIKky'], 'value': 1}, {'thru': ['transactionGk0J9', 'transactionLumFi', 'transaction3513f'], 'value': 1}, {'thru': ['transactionxEKhW', 'transactionpF9ZR', 'transactiongxDaL'], 'value': 1}, {'thru': ['transactionGk0J9', 'transactioneq53y'], 'value': 1}, {'thru': ['transactioncUy0R', 'transactionQmilP', 'transactionBJYL4', 'transactioneq53y'], 'value': 1}, {'thru': ['transactionQmilP', 'transactionZu7GN', 'transactionYRE5t'], 'value': 1}, {'thru': ['transactiong8aLK', 'transactionEfkJq', 'transactionf9nWO'], 'value': 1}, {'thru': ['transactionnb1Rh', 'transactionYRE5t'], 'value': 1}, {'thru': ['transactionh98w1', 'transaction0uSMI'], 'value': 1}, {'thru': ['transactionh98w1', 'transactionWIeJ7'], 'value': 1}, {'thru': ['transactionslTfQ', 'transactionyWNrI', 'transactioneq53y'], 'value': 1}, {'thru': ['transaction2UE7q', 'transaction4FmhG'], 'value': 1}, {'thru': ['transactionZVCxv', 'transactionWIeJ7'], 'value': 1}, {'thru': ['transaction2UE7q', 'transactionDgcGW'], 'value': 1}, {'thru': ['transactionXWVmd', 'transactionz6o3P'], 'value': 1}, {'thru': ['transactionnb1Rh', 'transactiongxDaL'], 'value': 1}]}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def generate_random_name(prefix=''):\n",
    "    \"\"\"生成随机名称\"\"\"\n",
    "    return prefix + ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "\n",
    "def find_frequent_subsequences(sequences, length, removed_subsequences):\n",
    "    \"\"\"查找频繁出现的子序列\"\"\"\n",
    "    subseq_count = Counter()\n",
    "    for seq in sequences:\n",
    "        # 过滤掉已经被移除的子序列\n",
    "        filtered_seq = [x for x in seq if x not in removed_subsequences]\n",
    "        for i in range(len(filtered_seq) - length + 1):\n",
    "            sub = tuple(filtered_seq[i:i + length])\n",
    "            if not any(item.startswith('<removed_') for item in sub):\n",
    "                subseq_count[sub] += 1\n",
    "    return [subseq for subseq, count in subseq_count.items() if count > 1]\n",
    "\n",
    "def replace_subsequences(seq, subsequences_map, placeholder):\n",
    "    \"\"\"将子序列替换为占位符\"\"\"\n",
    "    replaced_seq = []\n",
    "    i = 0\n",
    "    while i < len(seq):\n",
    "        matched = False\n",
    "        for length in range(len(subsequences_map), 1, -1):  # 从最长到最短检查\n",
    "            if i + length <= len(seq):\n",
    "                sub = tuple(seq[i:i + length])\n",
    "                if sub in subsequences_map:\n",
    "                    replaced_seq.append(subsequences_map[sub])\n",
    "                    i += length\n",
    "                    matched = True\n",
    "                    break\n",
    "        if not matched:\n",
    "            replaced_seq.append(seq[i])\n",
    "            i += 1\n",
    "    return replaced_seq\n",
    "\n",
    "def process_sequences(sequences, lengths, placeholders):\n",
    "    \"\"\"逐步处理序列\"\"\"\n",
    "    processed_sequences = sequences[:]\n",
    "    all_node_maps = {}\n",
    "    removed_subsequences = set()\n",
    "    \n",
    "    for length, placeholder in zip(lengths, placeholders):\n",
    "        # 查找频繁子序列（排除已经被替换的子序列）\n",
    "        subsequences = find_frequent_subsequences(processed_sequences, length, removed_subsequences)\n",
    "        \n",
    "        # 生成节点映射\n",
    "        node_map = {subseq: generate_random_name(prefix=placeholder) for subseq in subsequences}\n",
    "        all_node_maps.update(node_map)\n",
    "        \n",
    "        # 更新已移除的子序列集合\n",
    "        removed_subsequences.update(node_map.keys())\n",
    "        print('removed_subsequences', removed_subsequences)\n",
    "        \n",
    "        # 替换子序列\n",
    "        processed_sequences = [replace_subsequences(seq, node_map, placeholder) for seq in processed_sequences]\n",
    "    \n",
    "    return processed_sequences, all_node_maps\n",
    "\n",
    "def generate_flows1(sequences, node_map):\n",
    "    \"\"\"生成流动数据\"\"\"\n",
    "    flows = []\n",
    "    for seq in sequences:\n",
    "        flow = {\"thru\": [node_map.get(x, x) for x in seq if x not in node_map], \"value\": 1}\n",
    "        flows.append(flow)\n",
    "    return flows\n",
    "\n",
    "def generate_flows(sequences, node_map):\n",
    "    \"\"\"生成流动数据\"\"\"\n",
    "    flows = []\n",
    "    \n",
    "    # 遍历每条序列\n",
    "    for seq in sequences:\n",
    "\n",
    "        # 创建流动数据的列表\n",
    "        updated_seq = []\n",
    "        \n",
    "        # 遍历序列中的每个项\n",
    "        for x in seq:\n",
    "            \n",
    "            if x not in node_map:\n",
    "                # 如果该项不在节点映射中，则生成新的名称并更新节点映射\n",
    "                new_name = generate_random_name(prefix='transaction')\n",
    "                node_map[x] = new_name\n",
    "            \n",
    "            # 使用节点名称或原始名称\n",
    "            updated_seq.append(node_map[x])\n",
    "        \n",
    "        # 添加到流动数据列表\n",
    "        flow = {\"thru\": updated_seq, \"value\": 1}\n",
    "        flows.append(flow)\n",
    "    print('node_map', node_map)\n",
    "    return flows\n",
    "\n",
    "def format_nodes(node_map):\n",
    "    \"\"\"格式化节点\"\"\"\n",
    "    nodes = []\n",
    "    for subseq, name in node_map.items():\n",
    "        nodes.append({\"disp\": subseq, \"name\": name})\n",
    "    return nodes\n",
    "\n",
    "def separate_removed_subsequences(sequences, removed_subsequences):\n",
    "    \"\"\"将已经移除的子序列单独处理\"\"\"\n",
    "    individual_nodes = {}\n",
    "    for subseq in removed_subsequences:\n",
    "        name = generate_random_name(prefix='<removed>')\n",
    "        individual_nodes[tuple(subseq)] = name\n",
    "    return individual_nodes\n",
    "\n",
    "# 原始数据\n",
    "sequences = [\n",
    "    ['Name1', 'Name2', 'Name3', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name10', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name7', 'Name8'],\n",
    "    ['Name1', 'Name2', 'Name3', 'Name9', 'Name12', 'Name13'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name15', 'Name16'],\n",
    "    ['Name17', 'Name4', 'Name5', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name3', 'Name9', 'Name10', 'Name14', 'Name18'],\n",
    "    ['Name3', 'Name9', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name9', 'Name10', 'Name19', 'Name18'],\n",
    "    ['Name20', 'Name6', 'Name7', 'Name8'],\n",
    "    ['Name21', 'Name11', 'Name19', 'Name18'],\n",
    "    ['Name22', 'Name10', 'Name8'],\n",
    "    ['Name22', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name14', 'Name18'],\n",
    "    ['Name1', 'Name23', 'Name24'],\n",
    "    ['Name25', 'Name11', 'Name8'],\n",
    "    ['Name1', 'Name23', 'Name26'],\n",
    "    ['Name27', 'Name23', 'Name26'],\n",
    "    ['Name21', 'Name11', 'Name8']\n",
    "]\n",
    "\n",
    "# 定义最小子序列长度和占位符\n",
    "lengths = [4, 3, 2]\n",
    "placeholders = ['<removed_4>', '<removed_3>', '<removed_2>']\n",
    "\n",
    "# 逐步处理序列\n",
    "processed_sequences, node_map = process_sequences(sequences, lengths, placeholders)\n",
    "\n",
    "# 生成占位符的单独节点\n",
    "removed_subsequences = {subseq for subseq, name in node_map.items() if '<removed>' in name}\n",
    "individual_nodes = separate_removed_subsequences(sequences, removed_subsequences)\n",
    "node_map.update(individual_nodes)\n",
    "\n",
    "# 生成流动数据\n",
    "flows = generate_flows(processed_sequences, node_map)\n",
    "\n",
    "# 格式化节点\n",
    "nodes = format_nodes(node_map)\n",
    "\n",
    "# 生成最终结果\n",
    "result = {\n",
    "    \"Data source\": \"[Robert J. MacG. Dawson](http://www.amstat.org/publications/jse/v3n3/datasets.dawson.html)\",\n",
    "    \"nodes\": nodes,\n",
    "    \"flows\": flows\n",
    "}\n",
    "\n",
    "print(result)\n",
    "\n",
    "# 保存为 JSON 文件\n",
    "with open('result_with_check11.json', 'w') as f:\n",
    "    json.dump(result, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
